global:
  debugging:
      enabled: true
  # ssp:
  #   global:
  #     env:
  #       # Default JVM sizing for all JVM pods (can be overridden per-service)
  #       # Leaves ~40% headroom for metaspace, code cache, threads, JNI, TLS, etc.
  #       jvmOpts: >-
  #         -XX:+UseContainerSupport
  #         -XX:MaxRAMPercentage=60
  #         -XX:InitialRAMPercentage=30
  #         -XX:MaxMetaspaceSize=256m
  #         -XX:+ExitOnOutOfMemoryError
   
ssp:
  deployment:
    size: custom
  availability:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  dbInitializer:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  dataseed:
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  vaultSecretsInitializer:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  geolocation:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  uiHelperSvc:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  opa:
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"
  adminconsole:
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  selfserviceconsole:
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  factor:
    # Was req=2Gi / limit=2Gi with -Xmx1Gi (too tight, native + metaspace can OOM)
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  geolocation:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  iarisk:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  scheduler:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 2Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"


  signin:
    # Already had MaxRAMPercentage=75 (a bit aggressive); align with default
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  admin:
    # Already had MaxRAMPercentage=75 (a bit aggressive); align with default
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  # ---- JVM services that already had 1Gi/2Gi: keep sizing, add jvm flags ----
  azserver:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  identity:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

  authMgr:
    env:
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=60
        -XX:InitialRAMPercentage=30
        -XX:MaxMetaspaceSize=256m
        -XX:+ExitOnOutOfMemoryError
    resources:
      requests:
        memory: 3Gi
      limits:
        memory: 3Gi
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"
  # ---- iaservice had Xms/Xmx=2Gi with req=3Gi/limit=3Gi: give more headroom ----
  iaservice:
    # Keep your explicit Xmx=2Gi; raise limit so native/metaspace/thread stacks have space
    resources:
      requests:
        memory: 4Gi
      limits:
        memory: 4Gi
    env:
      # You can keep javaXms/javaXmx as-is; add safety flags
      jvmOpts: >-
        -XX:+UseContainerSupport
        -XX:+ExitOnOutOfMemoryError
    podReplicaCount: "1"
    scaling:
      min: "1"
      max: "2"

#   featureFlags:
#     dataseed:
#       enabled: false
#       skipSchemaInit: false
#       logLevel: INFO
#     policyupdatecheck:
#       enabled: false
#     scheduler:
#       enabled: false
#     # DONOT REMOVE THIS FLAG. THIS IS BEING USED IN AUTHENTICATION FLOW TO DETERMINE IF THE SSPRISK SERVICE IS DEPLOYED
#     iarisk:
#       enabled: false
#     adminconsole:
#       enabled: false
#     systemconsole:
#       enabled: false
#     selfserviceconsole:
#       enabled: false
#     swagger:
#       enabled: false
#     uiframe:
#       option: "UNSET"
#     custommetrics:
#       enabled: false
#     signinSupportsLegacyBrowser:
#       enabled: false
#     availabilityMetrics:
#       enabled: false
#       maxConnectionTimeoutInSecs: 300
#     customLocationData:
#       enabled: false
#     idbridge:
#       enabled: false
#     riskpolicies:
#       enabled: false
#     onBehalfOfPrivilegedOperations:
#       enabled: false
  # ---- JVM services with request==limit (add headroom + jvmOpts) ----